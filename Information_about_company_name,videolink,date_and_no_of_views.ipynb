{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7mAE2Z-6h-d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from googleapiclient.discovery import build\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Define API key and YouTube API service\n",
        "api_key = 'xxxxxxxxxxxxxxxxxxxxxxxxx'\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "def get_channel_id(youtube, channel_username):\n",
        "    try:\n",
        "        # Search for the channel by username (which is part of the URL)\n",
        "        request = youtube.channels().list(\n",
        "            forUsername=channel_username,\n",
        "            part='id'\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        if 'items' in response and len(response['items']) > 0:\n",
        "            return response['items'][0]['id']\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching channel ID for {channel_username}: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_youtube_channel_ads(channel_id, start_year, end_year, max_ads=100):\n",
        "    start_date = f'{start_year}-01-01T00:00:00Z'\n",
        "    end_date = f'{end_year}-12-31T23:59:59Z'\n",
        "    ads_info = []\n",
        "    next_page_token = None\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            request = youtube.search().list(\n",
        "                channelId=channel_id,  # Filter by the specific channel ID\n",
        "                part='snippet',\n",
        "                publishedAfter=start_date,\n",
        "                publishedBefore=end_date,\n",
        "                type='video',\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            )\n",
        "            response = request.execute()\n",
        "\n",
        "            if 'items' in response:\n",
        "                for item in response['items']:\n",
        "                    video_date = item['snippet']['publishedAt']\n",
        "                    video_url = f\"https://www.youtube.com/watch?v={item['id']['videoId']}\"\n",
        "\n",
        "                    # Append the relevant data\n",
        "                    ads_info.append({\n",
        "                        'ChannelID': channel_id,\n",
        "                        'Date': video_date,\n",
        "                        'AdLink': video_url\n",
        "                    })\n",
        "\n",
        "            # Check if there's another page of results\n",
        "            next_page_token = response.get('nextPageToken')\n",
        "            if not next_page_token or len(ads_info) >= max_ads:\n",
        "                break\n",
        "\n",
        "            time.sleep(1)  # Pause to avoid hitting rate limits\n",
        "\n",
        "        # Randomly select up to max_ads ads from the list\n",
        "        if len(ads_info) > max_ads:\n",
        "            ads_info = random.sample(ads_info, max_ads)\n",
        "\n",
        "        return ads_info\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while fetching data for channel {channel_id}: {e}\")\n",
        "        return []\n",
        "\n",
        "def main():\n",
        "    # Load company names from CSV\n",
        "    df = pd.read_csv('/content/50comp.csv')  # Replace with your CSV file path\n",
        "    company_names = df['Name'].tolist()  # Adjust column name as per your CSV structure\n",
        "    all_ads_info = []\n",
        "\n",
        "    for company in company_names:\n",
        "        # Construct the YouTube username (part of the URL)\n",
        "        youtube_username = company  # The company name is used directly as part of the channel URL\n",
        "        channel_id = get_channel_id(youtube, youtube_username)\n",
        "\n",
        "        if channel_id:\n",
        "            # Fetch the channel's ads\n",
        "            ads_info = check_youtube_channel_ads(channel_id, 2021, 2024, max_ads=100)\n",
        "            all_ads_info.extend(ads_info)\n",
        "            print(f\"Company: {company}, Number of Ads Found: {len(ads_info)}\")\n",
        "        else:\n",
        "            print(f\"Channel not found for {company}.\")\n",
        "\n",
        "        time.sleep(1)  # Sleep to avoid hitting rate limits\n",
        "\n",
        "    # Save results to a new CSV file\n",
        "    if all_ads_info:  # Check if there's any data to save\n",
        "        ads_df = pd.DataFrame(all_ads_info)\n",
        "        ads_df.to_csv('youtube_channel_ads_info.csv', index=False)\n",
        "        print(\"Results saved to youtube_channel_ads_info.csv\")\n",
        "    else:\n",
        "        print(\"No advertisements found for any company in the specified period.\")\n"
      ]
    }
  ]
}